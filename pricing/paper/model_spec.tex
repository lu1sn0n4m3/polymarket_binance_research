\documentclass[11pt, a4paper]{article}

% --- Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb, amsthm}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{natbib}

\hypersetup{
    colorlinks=true,
    linkcolor=blue!60!black,
    citecolor=blue!60!black,
    urlcolor=blue!60!black,
}

% --- Theorem environments ---
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{assumption}{Assumption}

% --- Custom commands ---
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\sigEff}{\sigma_{\mathrm{eff}}}
\newcommand{\sigTod}{\sigma_{\mathrm{tod}}}
\newcommand{\sigRv}{\sigma_{\mathrm{rv}}}
\newcommand{\sigRel}{\sigma_{\mathrm{rel}}}

\title{\textbf{A Variance-First Framework for Binary Option Pricing\\under Gaussian Innovations}\\[0.5em]
\large Model Specification and Theoretical Foundations}
\author{}
\date{February 2026}

\begin{document}
\maketitle

% ===================================================================
\begin{abstract}
We provide a complete mathematical specification for a Gaussian binary option pricing model applicable to
high-frequency cryptocurrency markets. The model targets honest conditional
variance forecasting via the QLIKE proper scoring rule, then maps the variance forecast
to binary probabilities through the Gaussian CDF. The model
has four parameters ($c$, $\alpha$, $k_0$, $k_1$) controlling the conditional variance forecast,
which incorporates horizon-dependent shrinkage
toward the seasonal baseline, reverting the regime-responsiveness term at longer horizons where
transient volatility deviations are less informative. We state all assumptions explicitly, prove the key properties (QLIKE properness
and honest variance forecasts), develop a rigorous
diagnostic framework based on conditional calibration of normalized squared returns, and specify the
complete pricer construction from raw tick data to real-time probability output. The document is self-contained
and purely theoretical; empirical results are reported separately.
\end{abstract}

\tableofcontents
\newpage

% ===================================================================
\section{Introduction and Problem Statement}
\label{sec:intro}

\subsection{The binary pricing problem}

Consider an asset with price process $(S_t)_{t \geq 0}$ observed in continuous time. A binary option contract
is defined by a strike price $K > 0$ and an expiry time $T > 0$. The contract pays 1 if $S_T > K$ and 0 otherwise.
At any time $t < T$, the fair price of this contract under the physical measure is:
\begin{equation}
    p_t := \Prob(S_T > K \mid \F_t),
    \label{eq:binary_price}
\end{equation}
where $(\F_t)_{t \geq 0}$ is the natural filtration of the price process and $\Prob$ denotes the physical
probability measure.

\begin{remark}
In standard option pricing theory, one prices under a risk-neutral measure $\mathbb{Q}$. We work under the
physical measure $\Prob$ for two reasons: (i)~the contracts considered settle against the realized spot price,
so the pricing problem is equivalent to probability forecasting under $\Prob$; (ii)~at hourly horizons, the
expected return under $\Prob$ is negligible relative to the standard deviation (see Assumption~\ref{ass:zero_drift}),
so the distinction between $\Prob$ and $\mathbb{Q}$ is immaterial for binary pricing.
\end{remark}

\subsection{Log-return representation}

Define the terminal log-return and the log-strike distance:
\begin{align}
    r_{t,T} &:= \ln\!\left(\frac{S_T}{S_t}\right), \label{eq:log_return} \\
    k_t &:= \ln\!\left(\frac{K}{S_t}\right). \label{eq:log_strike}
\end{align}
Then $S_T > K$ if and only if $r_{t,T} > k_t$, and the pricing problem becomes:
\begin{equation}
    p_t = \Prob(r_{t,T} > k_t \mid \F_t) = 1 - F_{r_{t,T} \mid \F_t}(k_t),
    \label{eq:p_as_cdf}
\end{equation}
where $F_{r_{t,T} \mid \F_t}$ is the conditional CDF of $r_{t,T}$ given $\F_t$.

\subsection{Design philosophy}

To evaluate \eqref{eq:p_as_cdf}, one must specify the full conditional distribution of $r_{t,T}$.
Under a Gaussian innovation assumption, this reduces to forecasting the conditional variance
of $r_{t,T}$ (the conditional mean is negligible at short horizons).
The key design principle is that the variance is calibrated with a \emph{proper scoring rule} (QLIKE),
ensuring that the variance forecast is honest. We call this the \emph{variance-first} approach.


% ===================================================================
\section{Assumptions}
\label{sec:assumptions}

We state the assumptions under which the model operates. These are motivated by the structure of
high-frequency cryptocurrency price data at horizons of seconds to one hour.

\begin{assumption}[Zero conditional drift]
\label{ass:zero_drift}
The conditional expected log-return satisfies
\begin{equation}
    \E[r_{t,T} \mid \F_t] \approx 0
\end{equation}
in the sense that $|\E[r_{t,T} \mid \F_t]| \ll \sqrt{\Var(r_{t,T} \mid \F_t)}$ for all $t$ and $T-t \leq 3600$\,s.
\end{assumption}

\begin{remark}
For a continuous semimartingale with bounded drift $\mu$ and volatility $\sigma$, the expected log-return over
horizon $\tau = T - t$ is $\mu\tau - \frac{1}{2}\sigma^2\tau$, while the standard deviation is $\sigma\sqrt{\tau}$.
The ratio is $|\mu\tau - \frac{1}{2}\sigma^2\tau| / (\sigma\sqrt{\tau}) = O(\sqrt{\tau})$, which vanishes as $\tau \to 0$.
At $\tau = 3600$\,s and typical cryptocurrency volatility $\sigma \sim 4 \times 10^{-5}\,\text{s}^{-1/2}$,
this ratio is of order $10^{-3}$. We therefore treat the conditional mean as zero.
\end{remark}

\begin{assumption}[Finite conditional second moment]
\label{ass:finite_second}
The conditional second moment exists and is positive:
\begin{equation}
    0 < \E[r_{t,T}^2 \mid \F_t] < \infty \qquad \text{a.s.\ for all } t < T.
\end{equation}
\end{assumption}

\begin{assumption}[Conditional independence of scale and shape]
\label{ass:scale_shape}
There exists a measurable function $v_t(\tau) > 0$ (the \emph{conditional variance forecast}) and a random
variable $\varepsilon_t$ such that:
\begin{equation}
    r_{t,T} = \sqrt{v_t(\tau)}\,\varepsilon_t,
    \label{eq:decomp}
\end{equation}
where $\varepsilon_t$ has $\E[\varepsilon_t \mid \F_t] = 0$, $\Var(\varepsilon_t \mid \F_t) = 1$, and the
conditional distribution of $\varepsilon_t$ given $\F_t$ depends on $\F_t$ only through a finite-dimensional
sufficient statistic.
\end{assumption}

\begin{remark}
Assumption~\ref{ass:scale_shape} is the central structural assumption. It asserts that the conditional
distribution of $r_{t,T}$ factors into a scale component $\sqrt{v_t(\tau)}$ (which captures all the
conditional variance dynamics) and a shape component $\varepsilon_t$ (which captures the standardized
distributional form). This factorization is exact for any location-scale family and holds approximately
for a much wider class of models. Under the Gaussian assumption $\varepsilon_t \sim \mathcal{N}(0,1)$,
the calibration reduces to targeting $v_t(\tau)$ via QLIKE.
\end{remark}

\begin{assumption}[Stationarity of the innovation distribution]
\label{ass:stationary_innovation}
The conditional distribution of $\varepsilon_t$ given $\F_t$ is stationary over the calibration window.
Under the Gaussian assumption, this is automatically satisfied since the standard normal distribution
has no free shape parameters.
\end{assumption}

\begin{assumption}[QLIKE regularity]
\label{ass:qlike_regularity}
The parametric family $\{v_t(\tau;\theta) : \theta \in \Theta\}$ satisfies:
\begin{enumerate}[nosep, label=(\alph*)]
    \item $\Theta \subset \R^d$ is compact.
    \item $\theta \mapsto v_t(\tau;\theta)$ is continuous and bounded away from zero and infinity on $\Theta$.
    \item There exists $\theta^* \in \Theta$ such that $v_t(\tau;\theta^*) = \E[r_{t,T}^2 \mid \F_t]$ a.s.
\end{enumerate}
\end{assumption}


% ===================================================================
\section{Conditional Variance Model}
\label{sec:stage1}

\subsection{Variance-first decomposition}

Under Assumptions~\ref{ass:zero_drift}--\ref{ass:scale_shape}, the conditional variance of the terminal
log-return equals its conditional second moment:
\begin{equation}
    \Var(r_{t,T} \mid \F_t) = \E[r_{t,T}^2 \mid \F_t] - \underbrace{\E[r_{t,T} \mid \F_t]^2}_{\approx\, 0}
    \approx \E[r_{t,T}^2 \mid \F_t].
    \label{eq:var_equals_second_moment}
\end{equation}
We model this quantity directly as $v_t(\tau;\theta)$, a parametric function of observable features
and remaining time $\tau = T - t$. The variance has units of (log-return)$^2$, matching $r_{t,T}^2$.

\subsection{Input features}
\label{sec:features}

The variance forecast is constructed from observable quantities computed on high-frequency tick data.

\subsubsection{Tick-time realized variance}

Let $(p_j, t_j)_{j=1,2,\ldots}$ denote the sequence of mid-price observations at times $t_j$ where the
mid-price actually changed (i.e.\ $p_j \neq p_{j-1}$). Define the log-returns and time intervals:
\begin{equation}
    \Delta x_j := \ln(p_j / p_{j-1}), \qquad \Delta t_j := t_j - t_{j-1}.
    \label{eq:tick_returns}
\end{equation}

The \emph{tick-time realized variance} over a window $[a,b]$ is:
\begin{equation}
    \widehat{\mathrm{RV}}_{[a,b]} := \frac{\sum_{j:\,t_j \in [a,b]} (\Delta x_j)^2}
                                          {\sum_{j:\,t_j \in [a,b]} \Delta t_j}.
    \label{eq:rv_tick}
\end{equation}
This estimator normalizes by elapsed real time (not the number of ticks), yielding a per-second variance
estimate. The tick-time construction avoids the bias that arises in calendar-time realized variance when the
price is stale: if the mid-price does not change for an interval, no artificial zero returns are included
in the sum.

\begin{remark}
The estimator \eqref{eq:rv_tick} is consistent for the integrated variance of the continuous-time price
process under standard regularity conditions (finite activity jumps, bounded volatility). Its key advantage
over calendar-time realized variance is robustness to irregular price arrivals, which are prevalent in
24-hour cryptocurrency markets.
\end{remark}

\subsubsection{Seasonal volatility curve}

Partition the 24-hour day into $B = 288$ time-of-day buckets (five-minute buckets). For each
bucket $b \in \{1, \ldots, B\}$ and each calendar day $d$ in the calibration sample, compute the tick-time
realized volatility:
\begin{equation}
    \hat{\sigma}_{d,b} := \sqrt{\widehat{\mathrm{RV}}_{[a_{d,b},\, a_{d,b}+\Delta]}},
    \label{eq:sigma_day_bucket}
\end{equation}
where $[a_{d,b},\, a_{d,b}+\Delta]$ is the time interval corresponding to bucket $b$ on day $d$ and
$\Delta$ is the bucket width. The seasonal volatility curve is defined as the cross-day median:
\begin{equation}
    \sigTod(b) := \mathrm{median}_{d}\,\hat{\sigma}_{d,b},
    \label{eq:sigma_tod}
\end{equation}
Before aggregation, the squared tick returns $(\Delta x_j)^2$ are winsorized at the $(1-q)$th percentile
(default $q = 0.01$) to limit the influence of microstructure outliers (e.g.\ flash wicks). The seasonal
curve is then circularly smoothed using a uniform (box) kernel of width $2W+1$ buckets on the periodic
domain $[0, 24)$\,h (default $W = 3$, yielding a 35-minute window) and floored at $\sigTod(b) \geq 10^{-10}$
to prevent numerical issues in buckets with negligible tick activity.

\begin{remark}
The median is used instead of the mean for robustness to outlier days (news events, flash crashes). The
uniform circular smoothing respects the periodicity of the time-of-day domain. The resulting curve $\sigTod(b)$
is a non-parametric estimate of the ``typical'' volatility at each time of day.
\end{remark}

\subsubsection{Weekday--weekend split}

Cryptocurrency markets trade continuously, but the intraday volatility pattern differs between weekdays
and weekends (lower overall activity, different time-of-day peaks). We estimate separate seasonal curves
$\sigTod^{\mathrm{wd}}(b)$ and $\sigTod^{\mathrm{we}}(b)$ on weekday and weekend subsets of the
calibration window, and dispatch by calendar day at pricing time.

\subsubsection{Integrated seasonal volatility}

A point lookup $\sigTod(b_t)$ uses only the current bucket's volatility. For a contract with remaining
life $\tau$, the relevant quantity is the average variance over the entire interval $[t, t+\tau]$. Define
the \emph{integrated seasonal volatility}:
\begin{equation}
    \bar{\sigma}_{\mathrm{tod}}^2(t,\tau) := \frac{1}{\tau}\int_{t}^{t+\tau} \sigTod(s)^2\,ds,
    \label{eq:sigma_tod_integrated}
\end{equation}
where $\sigTod(s)$ is evaluated at the bucket containing time $s$ (with weekday/weekend dispatch).
This is computed by summing $\sigTod(b)^2 \cdot (\text{overlap seconds})$ across the 5-minute buckets
that span $[t, t+\tau]$.

\begin{remark}
The integrated form is important near intraday transitions. For example, when pricing at 13:25~UTC
(a quiet period) with $\tau = 35$~min, the remaining life extends into 14:00~UTC (U.S.\@ equity open),
where volatility is $2$--$3\times$ higher. A point estimate would miss this; the integrated form
captures it. Throughout the remainder of this document, $\sigTod$ refers to the integrated quantity
$\bar{\sigma}_{\mathrm{tod}}(t,\tau)$ unless otherwise noted.
\end{remark}

\subsubsection{Real-time realized volatility}

The current volatility regime is tracked by an exponentially weighted moving average (EWMA) of the
tick-time realized variance:
\begin{equation}
    \sigRv(t) := \sqrt{\frac{\sum_{j:\,t_j \leq t} w_j\,(\Delta x_j)^2}
                             {\sum_{j:\,t_j \leq t} w_j\,\Delta t_j}},
    \qquad w_j := 2^{-(t - t_j)/H},
    \label{eq:sigma_rv}
\end{equation}
where $H > 0$ is the half-life parameter (in seconds; default $H = 600$). The exponential weighting ensures
that the estimator responds to regime changes with a characteristic time of $H / \ln 2$ seconds.
The EWMA accumulators are initialized using the first $\min(100, \lfloor N/10 \rfloor)$ tick
observations (where $N$ is the total number of ticks) to avoid dependence on an arbitrary prior
during cold-start.

\subsubsection{Relative regime level}

The relative volatility measures how the current regime compares to the seasonal norm over the
contract's remaining life:
\begin{equation}
    \sigRel(t,\tau) := \frac{\sigRv(t)}{\bar{\sigma}_{\mathrm{tod}}(t,\tau)},
    \label{eq:sigma_rel}
\end{equation}
where $\bar{\sigma}_{\mathrm{tod}}(t,\tau)$ is the integrated seasonal volatility (\ref{eq:sigma_tod_integrated}).
Values $\sigRel > 1$ indicate an elevated regime; $\sigRel < 1$ indicates suppressed volatility
relative to the seasonal expectation.

\begin{remark}
The use of the integrated seasonal denominator makes $\sigRel$ horizon-dependent: the same
$\sigRv(t)$ yields different $\sigRel$ values for contracts with different remaining lives.
This is deliberate---a contract expiring before a known volatility spike should have a different
regime assessment than one expiring after it.
\end{remark}

\subsection{Parametric variance model}

We combine the features into a multiplicative variance forecast with state-dependent shrinkage:
\begin{equation}
    \boxed{
    v_t(\tau;\theta) = c^2 \;\cdot\; \sigTod(t,\tau)^2 \;\cdot\; \tau^{\alpha}
    \;\cdot\; \bigl[\,m_t(\tau) + (1 - m_t(\tau))\,\sigRel(t,\tau)^{2}\,\bigr],
    }
    \label{eq:v_model}
\end{equation}
where $\sigTod(t,\tau) \equiv \bar{\sigma}_{\mathrm{tod}}(t,\tau)$ is the integrated seasonal volatility
\eqref{eq:sigma_tod_integrated}, and the \emph{shrinkage weight} $m_t(\tau) \in (0,1)$ is defined by:
\begin{equation}
    \boxed{
    m_t(\tau) := \sigma\!\bigl(k_0 + k_1 \ln\tau\bigr),
    }
    \label{eq:shrinkage}
\end{equation}
with $\sigma(x) = 1/(1+e^{-x})$ the sigmoid function.
The full parameter vector is $\theta = (c, \alpha, k_0, k_1)$.

\begin{remark}[Interpretation of the shrinkage factor]
\label{rem:v_interpretation}
\hfill

The factor $f_t := m_t + (1 - m_t)\,\sigRel^{2}$ interpolates between two extremes:
\begin{itemize}[nosep]
    \item $m_t = 0$: Full regime pass-through. $f_t = \sigRel^{2}$, recovering the pure
        power-law model.
    \item $m_t = 1$: Full seasonal reversion. $f_t = 1$, so $v_t = c^2\,\sigTod^2\,\tau^\alpha$---the
        model ignores $\sigRel$ entirely and prices from the seasonal curve alone.
\end{itemize}
The two sigmoid inputs control the shrinkage:
\begin{itemize}[nosep]
    \item $k_0$: Baseline shrinkage level.
    \item $k_1 \ln\tau$: Horizon-dependent shrinkage. When $k_1 > 0$, longer horizons induce stronger
        reversion to seasonal---consistent with the intuition that short-lived volatility spikes
        matter less for longer-dated contracts.
\end{itemize}
This two-parameter form is deliberately parsimonious. The shrinkage depends only on the horizon
$\tau$, not on $\sigRel$ itself, so that the regime signal enters the variance exclusively through
the power-law $\sigRel^{2}$.
\end{remark}

\begin{remark}[Remaining components]
\hfill
\begin{itemize}[nosep]
    \item $c^2$: Overall variance scale. Absorbs systematic biases in the input estimators.
    \item $\sigTod(t,\tau)^2$: Integrated intraday seasonal pattern. Captures the $5$--$10\times$
        variance ratio between active and quiet periods, averaged over the contract's remaining life.
    \item $\sigRel(t,\tau)^{2}$: Regime responsiveness. The squared term gives linear variance
        response to deviations from the seasonal norm, modulated by the shrinkage weight.
    \item $\tau^{\alpha}$: Horizon scaling. $\alpha = 1$ for a pure diffusion; $\alpha < 1$ for
        mean-reverting volatility; $\alpha > 1$ for regime-switching or trending volatility.
\end{itemize}
\end{remark}

\begin{remark}[Positivity and multiplicative structure]
The multiplicative structure \eqref{eq:v_model} ensures that $v_t(\tau;\theta) > 0$ for all parameter
values in the feasible region, without requiring explicit positivity constraints. The shrinkage factor
$f_t \in (0, \infty)$ is always positive since $m_t \in (0,1)$ and $\sigRel^{2} > 0$.
\end{remark}

\subsection{Calibration via the QLIKE scoring rule}
\label{sec:qlike}

\subsubsection{The QLIKE objective}

Given calibration observations $(r_i, \tau_i, \mathbf{x}_i)_{i=1}^N$, where $r_i$ is the realized log-return,
$\tau_i$ is the time to expiry, and $\mathbf{x}_i$ collects all features, define:
\begin{equation}
    \hat{v}_i := v_{t_i}(\tau_i;\theta).
\end{equation}
The QLIKE scoring rule is:
\begin{equation}
    \boxed{
    \mathrm{QLIKE}(\theta) := \frac{1}{N}\sum_{i=1}^{N} L_{\mathrm{Q}}(r_i^2, \hat{v}_i),
    \qquad L_{\mathrm{Q}}(y, v) := \ln v + \frac{y}{v}.
    }
    \label{eq:qlike}
\end{equation}

\subsubsection{Properness of QLIKE}

\begin{definition}[Proper scoring rule for the second moment]
\label{def:proper}
A scoring rule $S(y, v)$ for a non-negative target $y := r^2$ and a forecast $v > 0$ is \emph{proper}
if for all distributions of $y$ with finite mean $\mu = \E[y]$:
\begin{equation}
    \E[S(y, \mu)] \leq \E[S(y, v)] \qquad \text{for all } v > 0,
\end{equation}
with equality if and only if $v = \mu$. It is \emph{strictly proper} if the inequality is strict for $v \neq \mu$.
\end{definition}

\begin{proposition}[QLIKE is strictly proper]
\label{prop:qlike_proper}
The scoring rule $L_{\mathrm{Q}}(y, v) = \ln v + y/v$ is strictly proper for the conditional mean of $y = r^2$.
That is, for any random variable $y > 0$ with $\E[y] = \mu \in (0,\infty)$:
\begin{equation}
    \E[L_{\mathrm{Q}}(y, v)] \text{ is uniquely minimized at } v = \mu.
\end{equation}
\end{proposition}

\begin{proof}
Fix any $v > 0$. Compute:
\begin{equation}
    \E[L_{\mathrm{Q}}(y,v)] = \ln v + \frac{\mu}{v}.
\end{equation}
This is a function of $v$ alone (since $\E[y] = \mu$ is fixed). Taking the derivative:
\begin{equation}
    \frac{d}{dv}\left(\ln v + \frac{\mu}{v}\right) = \frac{1}{v} - \frac{\mu}{v^2} = \frac{v - \mu}{v^2}.
\end{equation}
Setting this to zero gives $v^* = \mu$. The second derivative is:
\begin{equation}
    \frac{d^2}{dv^2}\left(\ln v + \frac{\mu}{v}\right) = -\frac{1}{v^2} + \frac{2\mu}{v^3},
\end{equation}
which at $v = \mu$ equals $-1/\mu^2 + 2/\mu^2 = 1/\mu^2 > 0$, confirming a strict minimum.
Since $\ln v + \mu/v \to +\infty$ as $v \to 0^+$ or $v \to +\infty$, the minimum is global and unique.
\end{proof}

\begin{corollary}[Honest variance forecasts]
\label{cor:honest}
If the parametric family $\{v_t(\tau;\theta)\}$ is rich enough to represent $\E[r_{t,T}^2 \mid \F_t]$
(Assumption~\ref{ass:qlike_regularity}(c)), then QLIKE minimization produces:
\begin{equation}
    \hat{v}_i(\hat{\theta}) = \E[r_i^2 \mid \F_{t_i}] \qquad \text{a.s.\ at the population optimum,}
\end{equation}
where $\hat{\theta}$ is the QLIKE minimizer. We call this the \emph{honest variance} property.
\end{corollary}

\begin{remark}[Why not binary log-loss for variance calibration?]
\label{rem:why_not_logloss}
Binary log-loss is a proper scoring rule for \emph{probabilities}, not for \emph{variances}. When
variance parameters are fitted by minimizing binary log-loss, the optimizer can exploit the nonlinear
map $v \mapsto p$ (through the Gaussian CDF) to improve probability predictions at the
cost of systematic variance bias. Concretely, the optimizer may inflate $v$ in regimes where $k_t \approx 0$
(near at-the-money), because a wider distribution assigns probability closer to 0.5, which has low binary
log-loss when the true probability is near 0.5. QLIKE prevents this by targeting variance directly.
\end{remark}

\subsubsection{Market-weighted QLIKE}
\label{sec:market_weighted}

In practice, observations are sampled within market hours (contracts), and markets with more intra-hour
observations should not dominate the objective. Let $\mathcal{M} = \{1, \ldots, M\}$ index distinct markets,
and let $\mathcal{I}_m$ be the set of observation indices belonging to market $m$, with $|\mathcal{I}_m| = n_m$.
The market-weighted QLIKE is:
\begin{equation}
    \overline{\mathrm{QLIKE}}(\theta) := \frac{1}{M}\sum_{m=1}^{M} \left(\frac{1}{n_m}\sum_{i \in \mathcal{I}_m}
    L_{\mathrm{Q}}(r_i^2, \hat{v}_i)\right).
    \label{eq:qlike_weighted}
\end{equation}
This gives each market equal influence, regardless of the number of within-market observations.


% ===================================================================
\section{Diagnostics: Conditional Calibration}
\label{sec:diagnostics}

\subsection{The normalized squared return}

Define the \emph{variance ratio} or \emph{normalized squared return}:
\begin{equation}
    u_i := \frac{r_i^2}{\hat{v}_i}.
    \label{eq:u_def}
\end{equation}

\begin{proposition}[Conditional calibration criterion]
\label{prop:u_criterion}
If $\hat{v}_i = \E[r_i^2 \mid \F_{t_i}]$ (i.e.\ the variance forecast is honest), then:
\begin{equation}
    \E[u_i \mid \F_{t_i}] = 1 \qquad \text{a.s.}
    \label{eq:u_one}
\end{equation}
Conversely, if $\E[u_i \mid X_i] \neq 1$ for some $\F_{t_i}$-measurable variable $X_i$, then the variance
forecast is conditionally biased with respect to $X_i$.
\end{proposition}

\begin{proof}
Immediate from $\E[u_i \mid \F_{t_i}] = \E[r_i^2 \mid \F_{t_i}] / \hat{v}_i = \hat{v}_i / \hat{v}_i = 1$.
For the converse, if $\E[u_i \mid X_i] \neq 1$ and $X_i$ is $\F_{t_i}$-measurable, then by the tower property
$\E[u_i \mid X_i] = \E[\E[u_i \mid \F_{t_i}] \mid X_i]$, so $\E[u_i \mid \F_{t_i}] = 1$ a.s.\ would imply
$\E[u_i \mid X_i] = 1$, a contradiction.
\end{proof}

\subsection{Practical diagnostic procedure}

Since $\F_{t_i}$ is infinite-dimensional, we test the condition $\E[u_i \mid X_i] \approx 1$ for a small set
of low-dimensional state variables $X_i$ observable at time $t_i$:

\begin{enumerate}[nosep]
    \item \textbf{Horizon:} $X = \tau$. Detects misspecification of the exponent $\alpha$ in $\tau^\alpha$.
    \item \textbf{Regime:} $X = \sigRel$. Detects misspecification of the shrinkage parameters
        $(k_0, k_1)$ or the EWMA half-life $H$.
    \item \textbf{Staleness:} $X = \Delta t_{\mathrm{last}}$, the elapsed time (in seconds) since the
        mid-price last changed. Detects whether stale-quote effects bias the variance forecast.
    \item \textbf{Hour of day:} $X = h_t$ (Eastern Time). Detects residual seasonality not captured
        by $\sigTod$.
\end{enumerate}

For each scalar diagnostic variable $X$, form equal-mass bins $B_1, \ldots, B_J$ and compute:
\begin{equation}
    \bar{u}(B_j) := \frac{1}{|B_j|}\sum_{i \in B_j} u_i,
    \qquad \text{with cluster-robust SE at the market level.}
    \label{eq:u_bin}
\end{equation}
A well-calibrated model produces $\bar{u}(B_j) \approx 1$ uniformly across bins.

\subsection{Minimal correction principle}

Each diagnostic failure should be addressed by adjusting a single structural parameter rather than
adding high-dimensional features:
\begin{itemize}[nosep]
    \item $\E[u \mid \tau]$ drifts with $\tau$: adjust $\alpha$.
    \item $\E[u \mid \sigRel]$ slopes: adjust the shrinkage coefficients $(k_0, k_1)$
        or filter half-life $H$.
    \item $\E[u \mid \Delta t_{\mathrm{last}}]$ deviates: investigate EWMA decay behavior
        during stale-quote periods.
    \item $\E[u \mid h_t]$ deviates by hour of day: re-estimate or re-smooth $\sigTod$.
\end{itemize}
The guiding principle is parsimony: each conditional-bias failure points to a specific model
mechanism, and the fix is a one-knob structural adjustment rather than an ex-post patch.


% ===================================================================
\section{The Gaussian Pricer}
\label{sec:gaussian_pricer}

Under the simplifying assumption that $\varepsilon_t \sim \mathcal{N}(0,1)$ (the standardized innovation
is Gaussian), the decomposition \eqref{eq:decomp} gives:
\begin{equation}
    r_{t,T} \mid \F_t \sim \mathcal{N}(0,\, v_t(\tau)),
\end{equation}
where we have used Assumption~\ref{ass:zero_drift} to set the mean to zero. The binary probability is then:
\begin{equation}
    \boxed{
    p_t = \Phi\!\left(-\frac{k_t}{\sqrt{v_t(\tau)}}\right)
    = \Phi\!\left(-\frac{\ln(K/S_t)}{\sqrt{v_t(\tau;\theta)}}\right),
    }
    \label{eq:p_gauss}
\end{equation}
where $\Phi$ is the standard normal CDF.

\begin{remark}[Drift term]
Under the geometric Brownian motion model $dS/S = \mu\,dt + \sigma\,dW$, the log-return has mean
$(\mu - \frac{1}{2}\sigma^2)\tau$ and the correct $z$-score includes a $\frac{1}{2}\sigma^2\tau$ correction.
Under Assumption~\ref{ass:zero_drift}, this correction is of order $\sigma^2\tau \sim 10^{-6}$ for hourly
horizons and is absorbed into the zero-mean approximation. We therefore omit it.
\end{remark}

\begin{remark}[Symmetry property]
At the money ($S_t = K$, i.e.\ $k_t = 0$), equation \eqref{eq:p_gauss} gives $p_t = \Phi(0) = 0.5$,
independent of volatility. This is a consequence of the zero-drift and symmetric-innovation assumptions,
and it is a desirable property for a contract that pays on $S_T > K$.
\end{remark}


% ===================================================================
\section{Proper Scoring Rules}
\label{sec:scoring_rules}

The variance-first approach is grounded in the theory of proper scoring rules \citep{gneiting2007strictly}.
This section provides the relevant theoretical background.

\subsection{Definitions}

\begin{definition}[Scoring rule]
A \emph{scoring rule} is a function $S(y, q)$ that assigns a numerical score to a forecast $q$ given an
outcome $y$. Lower scores indicate better forecasts (loss convention).
\end{definition}

\begin{definition}[Proper scoring rule]
A scoring rule $S(y, q)$ is \emph{proper} with respect to a class of distributions $\mathcal{P}$ if for all
$P \in \mathcal{P}$:
\begin{equation}
    \E_P[S(Y, q^*)] \leq \E_P[S(Y, q)] \qquad \text{for all forecasts } q,
\end{equation}
where $q^* = q^*(P)$ is the ``truthful'' forecast associated with $P$. It is \emph{strictly proper} if
equality holds only when $q = q^*$.
\end{definition}

\subsection{QLIKE as a proper rule for the second moment}

The QLIKE rule $L_{\mathrm{Q}}(y, v) = \ln v + y/v$ is strictly proper for the mean of $y = r^2$
(Proposition~\ref{prop:qlike_proper}). It belongs to the Bregman divergence family generated by
$\phi(v) = -\ln v$:
\begin{equation}
    L_{\mathrm{Q}}(y, v) = \phi(v) + \phi'(v)(y - v) + C(y) = -\ln v + \frac{y - v}{v} + (1 + \ln y)
    = \ln v + \frac{y}{v} + \text{const}(y).
\end{equation}
The constant $C(y) = 1 + \ln y$ depends only on the observation and is irrelevant for optimization.

\subsection{Binary log-loss as a proper rule for probabilities}

The binary log-loss (or logarithmic scoring rule) for outcome $Y \in \{0,1\}$ and probability forecast $p$ is:
\begin{equation}
    L_{\mathrm{LL}}(Y, p) := -Y\ln p - (1-Y)\ln(1-p).
    \label{eq:logloss}
\end{equation}
This is strictly proper for the Bernoulli parameter $p^* = \Prob(Y=1)$: the expected loss
$\E[L_{\mathrm{LL}}(Y, p)] = -p^*\ln p - (1-p^*)\ln(1-p)$ is uniquely minimized at $p = p^*$
(by the Gibbs inequality).


% ===================================================================
\section{Statistical Estimation}
\label{sec:estimation}

\subsection{QLIKE optimization}

The QLIKE objective \eqref{eq:qlike_weighted} is minimized over
$\theta = (c, \alpha, k_0, k_1)$ subject to box constraints:
\begin{equation}
    c \in [0.1,\, 3.0], \quad
    \alpha \in [0.5,\, 1.5], \quad
    k_0 \in [-10,\, 5], \quad
    k_1 \in [-3,\, 3].
    \label{eq:box_constraints}
\end{equation}
We use L-BFGS-B \citep{byrd1995limited}, a quasi-Newton method for bound-constrained optimization,
which requires gradients. The gradient of the QLIKE loss for a single observation is:
\begin{equation}
    \frac{\partial L_{\mathrm{Q}}}{\partial \theta_j}
    = \left(1 - \frac{r_i^2}{\hat{v}_i}\right) \cdot \frac{1}{\hat{v}_i} \cdot \frac{\partial \hat{v}_i}{\partial \theta_j}.
    \label{eq:qlike_grad}
\end{equation}
Write $B := \sigTod^2 \cdot \tau^\alpha$ (the ``base'' variance) and
$f := m + (1-m)\,\sigRel^{2}$ (the shrinkage factor), so $v = c^2 B f$.
The partial derivatives are:
\begin{align}
    \frac{\partial v}{\partial c} &= \frac{2v}{c}, \label{eq:dv_dc} \\
    \frac{\partial v}{\partial \alpha} &= v \cdot \ln\tau. \label{eq:dv_dalpha}
\end{align}
For the shrinkage coefficients, let $P := \sigRel^{2}$ and note
$\partial f / \partial k_j = (1 - P)\,m(1-m)\,\partial z / \partial k_j$, where
$z = k_0 + k_1\ln\tau$. Then:
\begin{equation}
    \frac{\partial v}{\partial k_j} = c^2 B \cdot (1 - P)\,m(1-m) \cdot
    \frac{\partial z}{\partial k_j}, \qquad j = 0,1,
    \label{eq:dv_dk}
\end{equation}
with $\partial z / \partial k_0 = 1$ and $\partial z / \partial k_1 = \ln\tau$.

\subsection{Cluster-robust standard errors}
\label{sec:standard_errors}

Observations within the same market hour are not independent (they share the same terminal price $S_T$
and are subject to common shocks). Standard errors must account for this clustering.

We use a cluster-level standard error that avoids Hessian computation. For any statistic of interest
(e.g.\ $\bar{u}$ in a diagnostic bin, or a per-observation loss), let $\bar{x}_m$ denote the
within-market mean for market $m$. The cluster-robust SE is:
\begin{equation}
    \mathrm{SE}_{\mathrm{cluster}} = \frac{\mathrm{sd}(\bar{x}_1, \ldots, \bar{x}_M)}{\sqrt{M}},
    \label{eq:cluster_var}
\end{equation}
where $\mathrm{sd}$ denotes the sample standard deviation with Bessel's correction. This treats each
market hour as an independent observation, accounting for the within-market dependence induced by the
shared terminal price $S_T$.


% ===================================================================
\section{Complete Pricer Construction}
\label{sec:pricer}

This section specifies the end-to-end procedure for constructing the pricer from raw data to real-time
probability output.

\subsection{Offline calibration pipeline}
\label{sec:offline}

\begin{enumerate}
    \item \textbf{Data preparation.}
    \begin{enumerate}[nosep, label=(\alph*)]
        \item Obtain tick-level best-bid-offer (BBO) data at 1-second resolution.
        \item For each market hour, record strike $K$ (hour-open mid-price), expiry $T$, and terminal
            price $S_T$ (hour-close mid-price).
        \item Sample calibration rows at regular intervals (e.g.\ every 60 seconds) within each market hour.
            Each row contains: $S_t$, $K$, $\tau = T - t$, $S_T$, and $r_{t,T} = \ln(S_T/S_t)$.
    \end{enumerate}

    \item \textbf{Feature construction.}
    \begin{enumerate}[nosep, label=(\alph*)]
        \item Compute tick-time returns and intervals \eqref{eq:tick_returns} from the BBO stream.
        \item Estimate separate weekday and weekend seasonal curves $\sigTod^{\mathrm{wd}}(b)$,
            $\sigTod^{\mathrm{we}}(b)$ via \eqref{eq:sigma_day_bucket}--\eqref{eq:sigma_tod}
            with circular smoothing.
        \item Compute per-row $\sigRv(t)$ via EWMA \eqref{eq:sigma_rv} with half-life $H$.
        \item For each calibration row, compute integrated seasonal volatility
            $\bar{\sigma}_{\mathrm{tod}}(t,\tau)$ via \eqref{eq:sigma_tod_integrated}
            and $\sigRel(t,\tau) = \sigRv(t)/\bar{\sigma}_{\mathrm{tod}}(t,\tau)$.
    \end{enumerate}

    \item \textbf{Calibration.}
    \begin{enumerate}[nosep, label=(\alph*)]
        \item Minimize market-weighted QLIKE \eqref{eq:qlike_weighted} over
            $\theta = (c, \alpha, k_0, k_1)$ with box constraints.
        \item Compute variance forecasts $\hat{v}_i = v_{t_i}(\tau_i;\hat\theta)$ for all calibration rows.
    \end{enumerate}

    \item \textbf{Diagnostics.}
    \begin{enumerate}[nosep, label=(\alph*)]
        \item Compute $u_i = r_i^2 / \hat{v}_i$.
        \item Check $\E[u \mid X] \approx 1$ for $X \in \{\tau, \sigRel, \Delta t_{\mathrm{last}}, h_t\}$.
        \item If diagnostics fail, iterate (adjust $\alpha$, re-smooth $\sigTod$, adjust
            shrinkage parameters $k_0, k_1$, or half-life $H$).
    \end{enumerate}
\end{enumerate}

\subsection{Online pricing}
\label{sec:online}

At each quote time $t$ with current mid-price $S_t$, strike $K$, and time to expiry $\tau$:

\begin{enumerate}[nosep]
    \item \textbf{Update features:} Compute $\sigRv(t)$ from the live tick stream via EWMA
        \eqref{eq:sigma_rv}.
    \item \textbf{Integrate seasonal:} Compute $\bar{\sigma}_{\mathrm{tod}}(t,\tau)$ by
        integrating the pre-computed seasonal curve over $[t, t+\tau]$
        (weekday or weekend curve as appropriate).
    \item \textbf{Regime level:} $\sigRel = \sigRv(t) / \bar{\sigma}_{\mathrm{tod}}(t,\tau)$.
    \item \textbf{Shrinkage:} $m = \sigma(k_0 + k_1\ln\tau)$,
        $f = m + (1-m)\,\sigRel^{2}$.
    \item \textbf{Compute variance:} $\hat{v} = c^2 \cdot \bar{\sigma}_{\mathrm{tod}}^2
        \cdot \tau^\alpha \cdot f$.
    \item \textbf{Compute log-strike:} $k = \ln(K/S_t)$.
    \item \textbf{Price:} $p = \Phi\!\left(-k / \sqrt{\hat{v}}\right)$.
\end{enumerate}

The entire computation involves elementary operations plus a single CDF evaluation and can be executed
in microseconds.

\subsection{Live monitoring}
\label{sec:monitoring}

The deployed model is monitored via two channels:

\begin{enumerate}[nosep]
    \item \textbf{Scale monitor:} Rolling estimates of $\bar{u} = \E[u]$ and $\E[u \mid X]$ across
        $(\tau, \sigRel, \Delta t_{\mathrm{last}}, h_t)$. Detects when the variance model drifts out of calibration.
    \item \textbf{Override knobs:} The parameters $(c, \alpha, k_0, k_1)$
        have interpretable effects. In an emergency, a trader can:
        \begin{itemize}[nosep]
            \item Increase $c$ to widen the variance forecast globally.
            \item Increase $k_0$ to shrink more aggressively toward the seasonal baseline.
            \item Decrease $\alpha$ to flatten the horizon scaling.
        \end{itemize}
\end{enumerate}


% ===================================================================
\section{Extensions and Generalizations}
\label{sec:extensions}

\subsection{Heavy-tailed innovations}

The Gaussian innovation assumption may be relaxed by replacing $\varepsilon_t \sim \mathcal{N}(0,1)$
with a heavier-tailed distribution. Any location-scale family $F_\phi$ with $\E[X] = 0$,
$\Var(X) = \sigma^2_\phi$ can be made variance-preserving by scaling $\varepsilon_t = X / \sigma_\phi$,
yielding the generalized pricing formula:
\begin{equation}
    p_t = 1 - F_\phi\!\left(\frac{k_t \cdot \sigma_\phi}{\sqrt{v_t(\tau)}}\right).
\end{equation}
The Student-$t$ family is a natural candidate (one ``knob'' controlling kurtosis with closed-form CDF),
though other choices (normal-inverse Gaussian, generalized hyperbolic) are also possible. Importantly,
the variance-preserving construction ensures that the QLIKE-calibrated variance $v_t(\tau)$ remains valid
regardless of the innovation distribution, so the tail shape can be calibrated independently.

\subsection{Non-zero drift}

If Assumption~\ref{ass:zero_drift} is relaxed (e.g.\ at longer horizons where expected returns become
non-negligible), the pricing formula generalizes to:
\begin{equation}
    p_t = \Phi\!\left(-\frac{k_t - \mu_t(\tau)}{\sqrt{v_t(\tau)}}\right),
\end{equation}
where $\mu_t(\tau) = \E[r_{t,T} \mid \F_t]$ is a drift forecast. The QLIKE objective targets the
\emph{centered} second moment $\E[(r - \mu)^2 \mid \F_t]$ instead:
\begin{equation}
    \mathrm{QLIKE}_{\text{centered}}(\theta, \mu) = \frac{1}{N}\sum_{i=1}^{N}
    \left[\ln \hat{v}_i + \frac{(r_i - \hat\mu_i)^2}{\hat{v}_i}\right].
\end{equation}
This adds a drift estimation sub-problem, which requires its own proper scoring rule (the squared error
loss is proper for the conditional mean).


% ===================================================================
\section{Summary of Notation}
\label{sec:notation}

\begin{table}[h]
\centering
\caption{Summary of principal symbols.}
\label{tab:notation}
\begin{tabular}{@{}ll@{}}
\toprule
Symbol & Meaning \\
\midrule
$S_t$ & Asset mid-price at time $t$ \\
$K$ & Strike price (hour-open mid-price) \\
$T$ & Contract expiry time \\
$\tau = T - t$ & Time to expiry (seconds) \\
$r_{t,T} = \ln(S_T/S_t)$ & Terminal log-return \\
$k_t = \ln(K/S_t)$ & Log-strike distance \\
$p_t = \Prob(S_T > K \mid \F_t)$ & Binary option fair price \\
\midrule
$B$ & Number of TOD buckets (default $288$ for 5-minute buckets) \\
$W$ & Smoothing half-width for $\sigTod$ (buckets; default $3$) \\
$\sigTod(b)$ & Seasonal volatility curve (per bucket) \\
$\bar{\sigma}_{\mathrm{tod}}(t,\tau)$ & Integrated seasonal vol over $[t, t+\tau]$ \\
$\sigRv(t)$ & EWMA realized volatility \\
$\sigRel(t,\tau) = \sigRv/\bar{\sigma}_{\mathrm{tod}}$ & Relative regime level \\
$H$ & EWMA half-life (seconds; default $600$) \\
$\Delta t_{\mathrm{last}}$ & Time since last mid-price change (seconds) \\
$h_t$ & Hour of day (Eastern Time) \\
\midrule
$v_t(\tau;\theta)$ & Parametric variance forecast \\
$c, \alpha$ & Variance scale, horizon exponent \\
$k_0, k_1$ & Shrinkage parameters (baseline, horizon) \\
$m_t(\tau)$ & State-dependent shrinkage weight \\
$u_i = r_i^2 / \hat{v}_i$ & Normalized squared return (diagnostic) \\
\midrule
$\Phi(\cdot)$ & Standard normal CDF \\
$\mathrm{QLIKE}$ & Proper scoring rule for variance \\
$L_{\mathrm{LL}}$ & Binary log-loss \\
\bottomrule
\end{tabular}
\end{table}


% ===================================================================
\bibliographystyle{plainnat}
\begin{thebibliography}{9}

\bibitem[Byrd et~al.(1995)]{byrd1995limited}
R.~H.~Byrd, P.~Lu, J.~Nocedal, and C.~Zhu.
\newblock A limited memory algorithm for bound constrained optimization.
\newblock \emph{SIAM Journal on Scientific Computing}, 16(5):1190--1208, 1995.

\bibitem[Gneiting and Raftery(2007)]{gneiting2007strictly}
T.~Gneiting and A.~E.~Raftery.
\newblock Strictly proper scoring rules, prediction, and estimation.
\newblock \emph{Journal of the American Statistical Association}, 102(477):359--378, 2007.

\bibitem[Patton(2011)]{patton2011volatility}
A.~J.~Patton.
\newblock Volatility forecast comparison using imperfect volatility proxies.
\newblock \emph{Journal of Econometrics}, 160(1):246--256, 2011.

\end{thebibliography}

\end{document}
